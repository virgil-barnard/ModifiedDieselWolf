{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6574aea",
   "metadata": {},
   "source": [
    "# Configurable NMformer Demo\n",
    "This notebook demonstrates training with the NMformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import notebook\n",
    "\n",
    "from dieselwolf.data.DigitalModulations import DigitalModulationDataset\n",
    "from dieselwolf.data.TransformsRF import (\n",
    "    Random_Fading,\n",
    "    RandomCarrierFrequency,\n",
    "    RandomAWGN,\n",
    "    AWGN,\n",
    "    Normalize_Amplitude_Range,\n",
    "    Fix_Dtype,\n",
    ")\n",
    "\n",
    "from dieselwolf.models import ConfigurableNMformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa7ccd8",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_sz = 128\n",
    "train_channel = torchvision.transforms.Compose([\n",
    "    Random_Fading(0.1, 1.0),\n",
    "    RandomCarrierFrequency(0.01),\n",
    "    RandomAWGN(0, 30),\n",
    "    Fix_Dtype(),\n",
    "])\n",
    "train_norm = torchvision.transforms.Compose([\n",
    "    Normalize_Amplitude_Range(data_keys=[\"data\", \"data_Tx\"]),\n",
    "    Fix_Dtype(data_keys=[\"data\", \"data_Tx\"]),\n",
    "])\n",
    "\n",
    "train_dataset = DigitalModulationDataset(\n",
    "    2**12,\n",
    "    num_samples=512,\n",
    "    transform=train_channel,\n",
    "    normalize_transform=train_norm,\n",
    "    min_samp=8,\n",
    "    max_samp=16,\n",
    "    need_tx=True,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_sz, shuffle=True, num_workers=16, pin_memory=True, drop_last=False\n",
    ")\n",
    "\n",
    "val_dataset = DigitalModulationDataset(\n",
    "    2**8,\n",
    "    num_samples=512,\n",
    "    transform=train_channel,\n",
    "    normalize_transform=train_norm,\n",
    "    min_samp=8,\n",
    "    max_samp=16,\n",
    "    need_tx=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_sz, shuffle=False, num_workers=16, pin_memory=True, drop_last=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62a2e5",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConfigurableNMformer(seq_len=512, num_classes=len(train_dataset.classes), conv_channels=[32,64], kernel_sizes=[3,3], nhead=4, num_layers=2, num_noise_tokens=2)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "conf_matrix = np.zeros((len(train_dataset.classes), len(train_dataset.classes)))\n",
    "conf_matrix_2 = np.zeros((len(val_dataset.classes), len(val_dataset.classes)))\n",
    "epoch_nums = 16\n",
    "best_accuracy = -1000\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in notebook.tqdm(range(epoch_nums), desc='Epoch'):\n",
    "    model.train()\n",
    "    for item in notebook.tqdm(train_loader, desc='Training', leave=False):\n",
    "        inputs = item['data'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch == epoch_nums - 1:\n",
    "            for i in range(inputs.shape[0]):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                conf_matrix[label, pred] += 1\n",
    "\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    for item in notebook.tqdm(val_loader, desc='Validation', leave=False):\n",
    "        inputs = item['data'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().cpu().data.numpy()\n",
    "        if epoch == epoch_nums - 1:\n",
    "            for i in range(inputs.shape[0]):\n",
    "                label = labels[i]\n",
    "                pred = predicted[i]\n",
    "                conf_matrix_2[label, pred] += 1\n",
    "    accuracy = correct / float(len(val_loader) * batch_sz)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "\n",
    "for i in range(len(conf_matrix_2)):\n",
    "    conf_matrix_2[i] = conf_matrix_2[i] / conf_matrix_2[i].sum()\n",
    "for i in range(len(conf_matrix)):\n",
    "    conf_matrix[i] = conf_matrix[i] / conf_matrix[i].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff7fd4",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conf_color(value):\n",
    "    return 'white' if value > 0.7 else 'black'\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(conf_matrix, cmap='Blues')\n",
    "ax[1].imshow(conf_matrix_2, cmap='Blues')\n",
    "classes = val_dataset.classes\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        num = conf_matrix[i, j] * 100\n",
    "        ax[0].text(j - 0.43, i + 0.1, f'{num:2.1f}%', color=conf_color(conf_matrix[i, j]), fontsize=12)\n",
    "        num = conf_matrix_2[i, j] * 100\n",
    "        ax[1].text(j - 0.43, i + 0.1, f'{num:2.1f}%', color=conf_color(conf_matrix_2[i, j]), fontsize=12)\n",
    "for aaxx in ax:\n",
    "    aaxx.set_xticks(np.arange(0, len(classes)))\n",
    "    aaxx.set_xticklabels(classes, fontsize=12)\n",
    "    aaxx.set_yticks(np.arange(0, len(classes)))\n",
    "    aaxx.set_yticklabels(classes, fontsize=12)\n",
    "    aaxx.set_ylabel('Actual', fontsize=14)\n",
    "    aaxx.set_xlabel('Predicted', fontsize=14)\n",
    "ax[0].set_title('Training Confusion Matrix: Avg = ' + f'{100 * conf_matrix.diagonal().mean():2.2f}%', fontsize=18)\n",
    "ax[1].set_title('Validation Confusion Matrix: Avg = ' + f'{100 * conf_matrix_2.diagonal().mean():2.2f}%', fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d15425",
   "metadata": {},
   "source": [
    "### Accuracy vs SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56edae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snrs = np.arange(-30, 31, 1)[::-1]\n",
    "results = []\n",
    "for sss in notebook.tqdm(snrs):\n",
    "    channel = torchvision.transforms.Compose([\n",
    "        Random_Fading(0.1, 1.0),\n",
    "        RandomCarrierFrequency(0.01),\n",
    "        AWGN(sss),\n",
    "        Fix_Dtype(),\n",
    "    ])\n",
    "    norm = torchvision.transforms.Compose([\n",
    "        Normalize_Amplitude_Range(data_keys=['data', 'data_Tx']),\n",
    "        Fix_Dtype(data_keys=['data', 'data_Tx']),\n",
    "    ])\n",
    "    dataset = DigitalModulationDataset(\n",
    "        2**12,\n",
    "        num_samples=512,\n",
    "        min_samp=8,\n",
    "        max_samp=8,\n",
    "        transform=channel,\n",
    "        normalize_transform=norm,\n",
    "        need_tx=True,\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=batch_sz, shuffle=True, num_workers=16, pin_memory=True, drop_last=False)\n",
    "    conf_matrix = np.zeros((len(dataset.classes), len(dataset.classes)))\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    for item in loader:\n",
    "        RXinputs = item['data'].to(device)\n",
    "        labels = item['label'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(RXinputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().cpu().data.numpy()\n",
    "        for i in range(RXinputs.shape[0]):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            conf_matrix[label, pred] += 1\n",
    "    for i in range(len(conf_matrix)):\n",
    "        conf_matrix[i] = conf_matrix[i] / conf_matrix[i].sum()\n",
    "    results.append(conf_matrix)\n",
    "results = np.array(results)\n",
    "acc_snr = np.array([np.diagonal(res).mean() for res in results])\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "ax.plot(snrs, acc_snr, linewidth=3)\n",
    "ax.set_xlim(-34, 48)\n",
    "ax.grid()\n",
    "ax.set_title('Modulation Classification Accuracy', fontsize=20)\n",
    "ax.set_ylabel('Accuracy', fontsize=18)\n",
    "ax.set_xlabel('SNR (dB)', fontsize=18)\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
